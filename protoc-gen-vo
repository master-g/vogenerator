#!/usr/bin/env python

import sys
import time
import os.path

'''Generate Java source file for VO from a ProtoBuf FileDescriptorSet.'''
vo_version = "vo-0.4-dev (c) 2017 MG"

try:
    # Add some dummy imports to keep packaging tools happy
    import google
    import distutils.util  # bbfreeze seems to need these
    import pkg_resources  # pyinstaller / protobuf 2.5 seem to need these
except:
    # Don't care, we will error out later if it is actually important.
    pass

try:
    import google.protobuf.text_format as text_format
    import google.protobuf.descriptor_pb2 as descriptor
    import google.protobuf.compiler.plugin_pb2 as plugin_pb2
except:
    sys.stderr.write('''
         *************************************************************
         *** Could not import the Google protobuf Python libraries ***
         *** Try installing package 'python-protobuf' or similar.  ***
         *************************************************************
    ''' + '\n')
    raise


# ---------------------------------------------------------------------------
#                    Options parsing for the .proto files
# ---------------------------------------------------------------------------


class Globals:
    '''Ugly global variables, should find a good way to pass these.'''
    verbose_options = False
    separate_options = []
    matched_namemasks = set()
    output_package = "com.mico.model.vo."

# ---------------------------------------------------------------------------
#                     Generation of single fields
# ---------------------------------------------------------------------------


# Values are tuple (Java type, pb type)
FieldD = descriptor.FieldDescriptorProto
datatypes = {
    FieldD.TYPE_BOOL: ('boolean', 'BOOL'),
    FieldD.TYPE_DOUBLE: ('double', 'DOUBLE'),
    FieldD.TYPE_FIXED32: ('int', 'FIXED32'),
    FieldD.TYPE_FIXED64: ('long', 'FIXED64'),
    FieldD.TYPE_FLOAT: ('float', 'FLOAT'),
    FieldD.TYPE_INT32: ('int', 'INT32'),
    FieldD.TYPE_INT64: ('long', 'INT64'),
    FieldD.TYPE_SFIXED32: ('int', 'SFIXED32'),
    FieldD.TYPE_SFIXED64: ('long', 'SFIXED64'),
    FieldD.TYPE_SINT32: ('int', 'SINT32'),
    FieldD.TYPE_SINT64: ('long', 'SINT64'),
    FieldD.TYPE_UINT32: ('int', 'UINT32'),
    FieldD.TYPE_UINT64: ('long', 'UINT64')
}


class Names:
    '''Keeps a set of nested names and formats them to Java identifier.'''

    def __init__(self, parts=()):
        if isinstance(parts, Names):
            parts = parts.parts
        self.parts = tuple(parts)

    def __str__(self):
        return self.parts[-1]
        # return '_'.join(self.parts)

    def __add__(self, other):
        if isinstance(other, (str, unicode)):
            return Names(self.parts + (other,))
        elif isinstance(other, tuple):
            return Names(self.parts + other)
        else:
            raise ValueError("Name parts should be of type str")

    def __eq__(self, other):
        return isinstance(other, Names) and self.parts == other.parts


def names_from_type_name(type_name):
    '''Parse Names() from FieldDescriptorProto type_name'''
    if type_name[0] != '.':
        raise NotImplementedError(
            "Lookup of non-absolute type names is not supported")
    return Names(type_name[1:].split('.'))


def process_enum_value_name(value_name):
    if value_name[0] == 'k':
        return value_name[1:]
    else:
        return value_name


class Enum:

    def __init__(self, desc, pkg):
        '''desc is EnumDescriptorProto'''
        self.name = desc.name
        self.package = pkg
        self.values = [(process_enum_value_name(x.name), x.number)
                       for x in desc.value]

    def __str__(self):
        enumname = self.name
        # variable = enumname[0].lower() + enumname[1:]
        valuelist = [(v[1]) for v in self.values]
        code = 'code'

        addDefaultInvalid = True
        for nv in self.values:
            if nv[0].lower() == 'unknown' or nv[0].lower == 'invalid':
                addDefaultInvalid = False
                break

        invalidvalue = min(valuelist) - 1
        invalidname = 'Unknown'

        if addDefaultInvalid:
            self.values.insert(0, (invalidname, invalidvalue))

        result = 'public enum %s {\n\n' % enumname
        result += ',\n'.join(["    %s(%d)" % x for x in self.values])
        result += ';\n\n'
        result += '    public int %s;\n\n' % code
        result += '    %s(int %s) { this.%s = %s; }\n\n' % (enumname,
                                                            code, code, code)
        result += '    public static %s valueOf(final int %s) {\n' % (
            enumname, code)
        result += '        for (%s c : %s.values()) {\n' % (enumname, enumname)
        result += '            if (%s == c.%s) return c;\n' % (code, code)
        result += '        }\n'
        result += '        return %s;\n' % invalidname
        result += '    }'
        result += '\n}'

        return result


class Field:

    def __init__(self, struct_name, desc):
        '''desc is FieldDescriptorProto'''
        self.tag = desc.number
        self.struct_name = struct_name
        self.name = desc.json_name
        self.default = None
        self.jtype = None

        if self.name == '':
            self.name = desc.name

        if desc.HasField('default_value'):
            self.default = desc.default_value

        # Check field rules, i.e. required/optional/repeated.
        if desc.label == FieldD.LABEL_REQUIRED:
            self.rules = 'REQUIRED'
        elif desc.label == FieldD.LABEL_OPTIONAL:
            self.rules = 'OPTIONAL'
        elif desc.label == FieldD.LABEL_REPEATED:
            self.rules = 'REPEATED'
        else:
            raise NotImplementedError(desc.label)

        # Decide the Java data type to use in the class.
        if desc.type in datatypes.keys():
            self.jtype, self.pbtype = datatypes[desc.type]
        elif desc.type == FieldD.TYPE_ENUM:
            self.pbtype = 'ENUM'
            self.jtype = names_from_type_name(desc.type_name)
            if self.default is not None:
                self.default = self.jtype + self.default
        elif desc.type == FieldD.TYPE_STRING:
            self.pbtype = 'STRING'
            self.jtype = 'String'
        elif desc.type == FieldD.TYPE_BYTES:
            self.pbtype = 'BYTES'
            self.jtype = 'byte[]'
        elif desc.type == FieldD.TYPE_MESSAGE:
            self.pbtype = 'MESSAGE'
            self.jtype = names_from_type_name(desc.type_name)
            if str(self.jtype).find('RspHead') != -1:
                self.jtype = Names(['RspHeadEntity'])
        else:
            raise NotImplementedError(desc.type)

    def __cmp__(self, other):
        return cmp(self.tag, other.tag)

    def __str__(self):
        result = '    public '
        if self.pbtype == 'MESSAGE' and self.rules == 'REPEATED':
            result += 'List<%s> ' % self.jtype
            if self.name[-1] != 's':
                self.name += 's'
        else:
            result += '%s ' % self.jtype

        result += '%s;' % self.name

        return result

    def shouldimportlist(self):
        return self.pbtype == 'MESSAGE' and self.rules == 'REPEATED'

    def shouldimportarray(self):
        return self.pbtype == 'BYTES'

    def shouldimportrsphead(self):
        return str(self.jtype).find('RspHead') != -1

    def stringify(self, isfirst):
        result = '"'
        if not isfirst:
            result += ', '
        result += '%s=' % self.name
        if self.pbtype == 'STRING':
            result += "'"
        if self.pbtype == 'BYTES':
            result += '" + Arrays.toString(%s)' % self.name
        else:
            result += '" + %s' % self.name
        if self.pbtype == 'STRING':
            result += " + '\\''"
        result += " +"

        return result

    def types(self):
        return ''


class ExtensionRange(Field):

    def __init__(self, struct_name, range_start):
        '''Implements a special pb_extension_t* field in an extensible message
            structure. The range_start signifies the index at which the extensions
            start. Not necessarily all tags above this are extensions, it is merely
            a speed optimization.
            '''
        self.tag = range_start
        self.struct_name = struct_name
        self.name = 'extensions'
        self.pbtype = 'EXTENSION'
        self.rules = 'OPTIONAL'
        self.allocation = 'CALLBACK'
        self.ctype = 'pb_extension_t'
        self.array_decl = ''
        self.default = None
        self.max_size = 0
        self.max_count = 0

    def __str__(self):
        return '    pb_extension_t *extensions;'

    def types(self):
        return ''

    def tags(self):
        return ''


class ExtensionField(Field):

    def __init__(self, struct_name, desc, field_options):
        self.fullname = struct_name + desc.name
        self.extendee_name = names_from_type_name(desc.extendee)
        Field.__init__(self, self.fullname + 'struct', desc, field_options)

        if self.rules != 'OPTIONAL':
            self.skip = True
        else:
            self.skip = False
            self.rules = 'OPTEXT'

    def tags(self):
        '''Return the #define for the tag number of this field.'''
        identifier = '%s_tag' % self.fullname
        return '#define %-40s %d\n' % (identifier, self.tag)

    def extension_decl(self):
        '''Declaration of the extension type in the .pb.h file'''
        if self.skip:
            msg = '/* Extension field %s was skipped because only "optional"\n' % self.fullname
            msg += '   type of extension fields is currently supported. */\n'
            return msg

        return ('extern const pb_extension_type_t %s; /* field type: %s */\n' %
                (self.fullname, str(self).strip()))

    def extension_def(self):
        '''Definition of the extension type in the .vo.java file'''

        if self.skip:
            return ''

        result = 'public class {\n'
        result += str(self)
        result += '\n} %s;\n\n' % self.struct_name
        result += ('static const pb_field_t %s_field = \n  %s;\n\n' %
                   (self.fullname, self.pb_field_t(None)))
        result += 'const pb_extension_type_t %s = {\n' % self.fullname
        result += '    NULL,\n'
        result += '    NULL,\n'
        result += '    &%s_field\n' % self.fullname
        result += '};\n'
        return result


# ---------------------------------------------------------------------------
#                   Generation of oneofs (unions)
# ---------------------------------------------------------------------------

class OneOf(Field):

    def __init__(self, struct_name, oneof_desc):
        self.struct_name = struct_name
        self.name = oneof_desc.name
        self.ctype = 'union'
        self.fields = []
        self.allocation = 'ONEOF'
        self.default = None
        self.rules = 'ONEOF'

    def add_field(self, field):
        if field.allocation == 'CALLBACK':
            raise Exception(
                "Callback fields inside of oneof are not supported (field %s)" % field.name)

        field.union_name = self.name
        field.rules = 'ONEOF'
        self.fields.append(field)
        self.fields.sort(key=lambda f: f.tag)

        # Sort by the lowest tag number inside union
        self.tag = min([f.tag for f in self.fields])

    def __cmp__(self, other):
        return cmp(self.tag, other.tag)

    def __str__(self):
        result = ''
        if self.fields:
            result += '    pb_size_t which_' + self.name + ";\n"
            result += '    union {\n'
            for f in self.fields:
                result += '    ' + str(f).replace('\n', '\n    ') + '\n'
            result += '    } ' + self.name + ';'
        return result

    def types(self):
        return ''.join([f.types() for f in self.fields])

    def get_dependencies(self):
        deps = []
        for f in self.fields:
            deps += f.get_dependencies()
        return deps

    def get_initializer(self, null_init):
        return '0, {' + self.fields[0].get_initializer(null_init) + '}'

    def default_decl(self, declaration_only=False):
        return None

    def tags(self):
        return '\n'.join([f.tags() for f in self.fields])

    def pb_field_t(self, prev_field_name):
        result = ',\n'.join([f.pb_field_t(prev_field_name)
                             for f in self.fields])
        return result

    def largest_field_value(self):
        return max([f.largest_field_value() for f in self.fields])


# ---------------------------------------------------------------------------
#                   Generation of messages (structures)
# ---------------------------------------------------------------------------


class Message:

    def __init__(self, names, desc, pkg):
        self.name = names
        self.package = pkg
        self.shouldimportlist = False
        self.shouldimportarray = False
        self.shouldimportrsphead = False
        self.fields = []
        self.oneofs = {}
        no_unions = []

        if hasattr(desc, 'oneof_decl'):
            for i, f in enumerate(desc.oneof_decl):
                oneof = OneOf(self.name, f)
                self.oneofs[i] = oneof
                self.fields.append(oneof)

        for f in desc.field:
            field = Field(self.name, f)
            if not self.shouldimportlist:
                self.shouldimportlist = field.shouldimportlist()
            if not self.shouldimportarray:
                self.shouldimportarray = field.shouldimportarray()
            if not self.shouldimportrsphead:
                self.shouldimportrsphead = field.shouldimportrsphead()
            if (hasattr(f, 'oneof_index') and
                    f.HasField('oneof_index') and f.oneof_index not in no_unions):
                if f.oneof_index in self.oneofs:
                    self.oneofs[f.oneof_index].add_field(field)
            else:
                self.fields.append(field)

        if len(desc.extension_range) > 0:
            range_start = min([r.start for r in desc.extension_range])
            self.fields.append(ExtensionRange(self.name, range_start))

        self.ordered_fields = self.fields[:]
        self.ordered_fields.sort()

    def get_dependencies(self):
        '''Get list of type names that this structure refers to.'''
        deps = []
        for f in self.fields:
            deps += f.get_dependencies()
        return deps

    def __str__(self):
        result = 'public class %s {\n' % self.name
        result += '\n'.join([str(f) for f in self.ordered_fields])
        result += '\n\n'
        result += '    @Override\n    public String toString() {'
        result += '\n        return "%s{" +' % self.name
        result += '\n               '
        result += '\n               '.join(
            [f.stringify(self.ordered_fields.index(f) == 0) for f in self.ordered_fields])
        result += "\n               '}';"
        result += '\n    }'
        result += '\n}'

        return result

    def types(self):
        return ''.join([f.types() for f in self.fields])

    def get_initializer(self, null_init):
        if not self.ordered_fields:
            return '{0}'

        parts = []
        for field in self.ordered_fields:
            parts.append(field.get_initializer(null_init))
        return '{' + ', '.join(parts) + '}'

    def default_decl(self, declaration_only=False):
        result = ""
        for field in self.fields:
            default = field.default_decl(declaration_only)
            if default is not None:
                result += default + '\n'
        return result

    def count_required_fields(self):
        '''Returns number of required fields inside this message'''
        count = 0
        for f in self.fields:
            if not isinstance(f, OneOf):
                if f.rules == 'REQUIRED':
                    count += 1
        return count

    def count_all_fields(self):
        count = 0
        for f in self.fields:
            if isinstance(f, OneOf):
                count += len(f.fields)
            else:
                count += 1
        return count

    def fields_declaration(self):
        result = 'extern const pb_field_t %s_fields[%d];' % (
            self.name, self.count_all_fields() + 1)
        return result

    def fields_definition(self):
        result = 'const pb_field_t %s_fields[%d] = {\n' % (
            self.name, self.count_all_fields() + 1)

        prev = None
        for field in self.ordered_fields:
            result += field.pb_field_t(prev)
            result += ',\n'
            if isinstance(field, OneOf):
                prev = field.name + '.' + field.fields[-1].name
            else:
                prev = field.name

        result += '    PB_LAST_FIELD\n};'
        return result


# ---------------------------------------------------------------------------
#                    Processing of entire .proto files
# ---------------------------------------------------------------------------


def iterate_messages(desc, names=Names()):
    '''Recursively find all messages. For each, yield name, DescriptorProto.'''
    if hasattr(desc, 'message_type'):
        submsgs = desc.message_type
    else:
        submsgs = desc.nested_type

    for submsg in submsgs:
        sub_names = names + submsg.name
        yield sub_names, submsg

        for x in iterate_messages(submsg, sub_names):
            yield x


def iterate_extensions(desc, names=Names()):
    '''Recursively find all extensions.
    For each, yield name, FieldDescriptorProto.
    '''
    for extension in desc.extension:
        yield names, extension

    for subname, subdesc in iterate_messages(desc, names):
        for extension in subdesc.extension:
            yield subname, extension


def parse_file(fdesc):
    '''Takes a FileDescriptorProto and returns tuple (enums, messages, extensions).'''

    enums = []
    messages = []
    extensions = []
    package = fdesc.package.split('.')[-1]

    if fdesc.package:
        base_name = Names(fdesc.package.split('.'))
    else:
        base_name = Names()

    for enum in fdesc.enum_type:
        enums.append(Enum(enum, package))

    for names, message in iterate_messages(fdesc, base_name):
        messages.append(Message(names, message, package))
        for enum in message.enum_type:
            enums.append(Enum(enum, package))

    for names, extension in iterate_extensions(fdesc, base_name):
        extensions.append(ExtensionField(names, extension))

    return enums, messages, extensions


def generate_source(dependencies, headername, enums, messages, extensions):
    '''Generate content for a source file.'''

    yield '/* Automatically generated VO entity code */\n'
    yield '/* Generated by %s at %s */\n\n' % (vo_version, time.asctime())

    # For now we don't need dependency
    # for dependency in dependencies:
    #     noext = os.path.splitext(dependency)[0]
    #     yield noext
    #     yield '\n'

    yield '/* Enum definitions */\n'
    for enum in enums:
        yield str(enum) + '\n\n'

    yield '/* Entity definitions */\n'
    for msg in messages:
        yield msg.types()
        yield str(msg) + '\n\n'


def build_element(element):
    '''Generate content for a source file.'''

    yield 'package %s%s;\n\n' % (Globals.output_package, element.package)
    yield '/* Automatically generated VO entity code */\n'
    yield '/* Generated by %s at %s */\n\n' % (vo_version, time.asctime())
    if isinstance(element, Message):
        if element.shouldimportrsphead:
            yield 'import com.mico.model.vo.newmsg.RspHeadEntity;\n\n'
        if element.shouldimportarray:
            yield 'import java.util.Arrays;\n'
        if element.shouldimportlist:
            yield 'import java.util.List;\n'
        yield '\n'
    yield str(element)


def build_source(response, results):
    enums = results['enums']
    messages = results['messages']

    for enum in enums:
        f = response.file.add()
        f.name = enum.name + '.java'
        f.content = ''.join(build_element(enum))

    for message in messages:
        f = response.file.add()
        f.name = '%s' % message.name + '.java'
        f.content = ''.join(build_element(message))


# ---------------------------------------------------------------------------
#                         Command line interface
# ---------------------------------------------------------------------------

def process_file(filename, fdesc):
    '''Process a single file.
      filename: The full path to the .proto or .pb source file, as string.
      fdesc: The loaded FileDescriptorSet, or None to read from the input file.

      Returns a dict:
          {'sourcename': Name of the source code file,
           'sourcedata': Data for the .java source code file
          }
      '''

    if not fdesc:
        data = open(filename, 'rb').read()
        fdesc = descriptor.FileDescriptorSet.FromString(data).file[0]

    Globals.matched_namemasks = set()

    # Parse the file
    enums, messages, extensions = parse_file(fdesc)

    # Decide the file names
    noext = os.path.splitext(filename)[0]
    sourcename = noext + '.vo.java'
    sourcebasename = os.path.basename(sourcename)

    # List of .proto files that should not be included in the Java file
    # even if they are mentioned in the source .proto.
    excludes = ['google/protobuf/descriptor.proto']
    dependencies = [d for d in fdesc.dependency if d not in excludes]
    sourcedata = ''.join(generate_source(dependencies, sourcebasename, enums,
                                         messages, extensions))

    return {'sourcename': sourcename, 'sourcedata': sourcedata, 'enums': enums, 'messages': messages}


def main_plugin():
    '''Main function when invoked as a protoc plugin.'''

    import sys
    if sys.platform == "win32":
        import os
        import msvcrt
        # Set stdin and stdout to binary mode
        msvcrt.setmode(sys.stdin.fileno(), os.O_BINARY)
        msvcrt.setmode(sys.stdout.fileno(), os.O_BINARY)

    # Read request message from stdin
    data = sys.stdin.read()
    request = plugin_pb2.CodeGeneratorRequest.FromString(data)

    response = plugin_pb2.CodeGeneratorResponse()

    for filename in request.file_to_generate:
        for fdesc in request.proto_file:
            if fdesc.name == filename:
                results = process_file(filename, fdesc)
                build_source(response, results)

    sys.stdout.write(response.SerializeToString())


if __name__ == '__main__':
    main_plugin()
